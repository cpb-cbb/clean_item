{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56778a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c94b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/v7b0ncfx1rz2xq3ffw1jfqp80000gn/T/ipykernel_25841/863391539.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path, encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/Users/caopengbo/Documents/code/clean_item/property_clusters_output_secondary.csv'\n",
    "df = pd.read_csv(csv_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591a2e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据行数: 339519\n",
      "过滤后数据行数: 120613\n",
      "cluster_id总共有 13745 个类别\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[(df['cluster_id'] != 'Others') & (df['cluster_total_frequency'] >= 10)]\n",
    "print(f'原始数据行数: {len(df)}')\n",
    "print(f'过滤后数据行数: {len(filtered_df)}')\n",
    "#\n",
    "cluster_count = filtered_df['cluster_id'].nunique()\n",
    "print(f'cluster_id总共有 {cluster_count} 个类别')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af669234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个cluster_id中count最高的行数: 13745\n"
     ]
    }
   ],
   "source": [
    "#只保留每个cluster_id中count最高的行-也就是用最高频词来作为该cluster_id的代表\n",
    "highest_df = filtered_df.loc[filtered_df.groupby('cluster_id')['cluster_total_frequency'].idxmax()]\n",
    "print(f'每个cluster_id中count最高的行数: {len(highest_df)}')\n",
    "#保存代表词文件\n",
    "\n",
    "output_highest_path = os.path.join(os.path.dirname(csv_path), 'highest_property_clusters_output_secondary.csv')\n",
    "\n",
    "highest_df.to_csv(output_highest_path, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6c8ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 完整Property值频次（前10个）===\n",
      "property\n",
      "Thickness                        1\n",
      "Transport energy gap value       1\n",
      "Intensity Ratio D°X/FXA          1\n",
      "ESR peak-to-peak linewidth       1\n",
      "Energy level scheme              1\n",
      "Vibrational Bands                1\n",
      "Moth-eye structure morphology    1\n",
      "Conversion depth                 1\n",
      "Internal loss (αi)               1\n",
      "Triplet State Lifetime           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== 主要术语频次（去括号内容）===\n",
      "'Composition': 33\n",
      "'Thickness': 13\n",
      "'Morphology': 13\n",
      "'Surface Morphology': 11\n",
      "'Interlayer Spacing': 10\n",
      "'Photocurrent': 9\n",
      "'Crystal Quality': 8\n",
      "'Crystal Structure': 7\n",
      "'Stability': 7\n",
      "'Stoichiometry': 7\n",
      "\n",
      "=== 核心关键词频次 ===\n",
      "energy: 679\n",
      "peak: 588\n",
      "emission: 425\n",
      "density: 409\n",
      "band: 399\n",
      "current: 375\n",
      "concentration: 340\n",
      "ratio: 333\n",
      "temperature: 332\n",
      "surface: 304\n",
      "intensity: 300\n",
      "presence: 298\n",
      "efficiency: 295\n",
      "structure: 250\n",
      "thickness: 248\n"
     ]
    }
   ],
   "source": [
    "# 统计filtered_df中property列所有关键词的词频\n",
    "# 简化版本 - 只统计最重要的信息\n",
    "import re\n",
    "from collections import Counter\n",
    "def simple_property_analysis(df, column_name='property'):\n",
    "    \n",
    "    # 1. 完整值统计\n",
    "    print(\"=== 完整Property值频次（前10个）===\")\n",
    "    print(df[column_name].value_counts().head(10))\n",
    "    print()\n",
    "    \n",
    "    # 2. 主要术语统计（去括号）\n",
    "    print(\"=== 主要术语频次（去括号内容）===\")\n",
    "    main_terms = []\n",
    "    for prop in df[column_name].dropna():\n",
    "        # 去除括号内容，清理空格\n",
    "        clean_term = re.sub(r'\\([^)]*\\)', '', str(prop)).strip()\n",
    "        clean_term = re.sub(r'\\s+', ' ', clean_term)  # 标准化空格\n",
    "        if clean_term:\n",
    "            main_terms.append(clean_term)\n",
    "    \n",
    "    main_counts = Counter(main_terms)\n",
    "    for term, count in main_counts.most_common(10):\n",
    "        print(f\"'{term}': {count}\")\n",
    "    print()\n",
    "    \n",
    "    # 3. 关键词统计\n",
    "    print(\"=== 核心关键词频次 ===\")\n",
    "    keywords = []\n",
    "    for prop in df[column_name].dropna():\n",
    "        words = re.findall(r'[A-Za-z]{3,}', str(prop))  # 提取3个字母以上的词\n",
    "        keywords.extend([w.lower() for w in words])\n",
    "    \n",
    "    # 过滤常见词\n",
    "    stop_words = {'from', 'and', 'the', 'inferred', 'implied'}\n",
    "    filtered_keywords = [w for w in keywords if w not in stop_words]\n",
    "    \n",
    "    keyword_counts = Counter(filtered_keywords)\n",
    "    for word, count in keyword_counts.most_common(15):\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "    return main_counts, keyword_counts\n",
    "\n",
    "# 运行简化分析\n",
    "main_counts, keyword_counts=simple_property_analysis(highest_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7ad1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主要术语保存到: /Users/caopengbo/Documents/code/clean_item/main_terms_results.csv\n",
      "关键词保存到: /Users/caopengbo/Documents/code/clean_item/keywords_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存为两个独立的CSV文件\n",
    "base_path = os.path.dirname(csv_path)\n",
    "\n",
    "# 保存主要术语\n",
    "main_terms_path = os.path.join(base_path, 'main_terms_results.csv')\n",
    "with open(main_terms_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Main Term,Count\\n\")\n",
    "    for term, count in main_counts.items():\n",
    "        f.write(f'\"{term}\",{count}\\n')\n",
    "\n",
    "# 保存关键词\n",
    "keywords_path = os.path.join(base_path, 'keywords_results.csv')\n",
    "with open(keywords_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"Keyword,Count\\n\")\n",
    "    for word, count in keyword_counts.items():\n",
    "        f.write(f\"{word},{count}\\n\")\n",
    "\n",
    "print(f\"主要术语保存到: {main_terms_path}\")\n",
    "print(f\"关键词保存到: {keywords_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce76590",
   "metadata": {},
   "source": [
    "上述是对filtered_df的属性列进行的简单分析（统计专业术语即去掉括号的频次，核心关键词的频次），结果已保存为CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14a2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对highest_df的高频词汇聚类，相似度较低，旨在为其构建上一级聚类\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "def perform_property_clustering(df, column_name='property', similarity_threshold=0.3, min_community_size=2):\n",
    "    \"\"\"\n",
    "    对property列进行聚类分析\n",
    "    \n",
    "    Args:\n",
    "        df: 包含property列的DataFrame\n",
    "        column_name: 要聚类的列名\n",
    "        similarity_threshold: 相似度阈值\n",
    "        min_community_size: 最小簇大小\n",
    "    \n",
    "    Returns:\n",
    "        聚类结果字典\n",
    "    \"\"\"\n",
    "    print(f\"\\n🤖 开始对{column_name}列进行聚类...\")\n",
    "    print(f\"  - 相似度阈值: {similarity_threshold}\")\n",
    "    print(f\"  - 最小簇大小: {min_community_size}\")\n",
    "    \n",
    "    # 准备数据\n",
    "    properties = df[column_name].dropna().tolist()\n",
    "    print(f\"  - 待聚类的属性数量: {len(properties)}\")\n",
    "    \n",
    "    # 加载模型并计算嵌入\n",
    "    print(\"  - 正在加载语言模型...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    print(\"  - 正在计算句子嵌入...\")\n",
    "    embeddings = model.encode(properties, convert_to_tensor=True)\n",
    "    \n",
    "    # 执行社区检测聚类\n",
    "    print(\"  - 正在执行聚类...\")\n",
    "    clusters = util.community_detection(\n",
    "        embeddings,\n",
    "        min_community_size=min_community_size,\n",
    "        threshold=similarity_threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 聚类完成！共找到 {len(clusters)} 个簇。\")\n",
    "    \n",
    "    # 处理聚类结果\n",
    "    clustered_indices = set()\n",
    "    clustered_results = []\n",
    "    \n",
    "    for i, cluster_indices in enumerate(clusters):\n",
    "        cluster_members = []\n",
    "        for idx in cluster_indices:\n",
    "            property_name = properties[idx]\n",
    "            # 从原始DataFrame中获取该property的频次信息\n",
    "            count = len(df[df[column_name] == property_name])\n",
    "            cluster_members.append({\n",
    "                'property': property_name,\n",
    "                'count': count\n",
    "            })\n",
    "        \n",
    "        clustered_results.append({\n",
    "            'cluster_id': f\"cluster_{i+1}\",\n",
    "            'size': len(cluster_members),\n",
    "            'members': cluster_members\n",
    "        })\n",
    "        clustered_indices.update(cluster_indices)\n",
    "    \n",
    "    # 识别未聚类的项目\n",
    "    all_indices = set(range(len(properties)))\n",
    "    unclustered_indices = all_indices - clustered_indices\n",
    "    unclustered_items = []\n",
    "    \n",
    "    for idx in unclustered_indices:\n",
    "        property_name = properties[idx]\n",
    "        count = len(df[df[column_name] == property_name])\n",
    "        unclustered_items.append({\n",
    "            'property': property_name,\n",
    "            'count': count\n",
    "        })\n",
    "    \n",
    "    print(f\"  - {len(clustered_indices)} 个属性被聚类\")\n",
    "    print(f\"  - {len(unclustered_indices)} 个属性未被聚类\")\n",
    "    \n",
    "    return {\n",
    "        'clustered_results': clustered_results,\n",
    "        'unclustered_items': unclustered_items,\n",
    "        'total_clusters': len(clusters),\n",
    "        'clustered_count': len(clustered_indices),\n",
    "        'unclustered_count': len(unclustered_indices)\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3de7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 开始对property列进行聚类...\n",
      "  - 相似度阈值: 0.5\n",
      "  - 最小簇大小: 2\n",
      "  - 待聚类的属性数量: 13744\n",
      "  - 正在加载语言模型...\n",
      "  - 正在计算句子嵌入...\n",
      "  - 正在执行聚类...\n",
      "✅ 聚类完成！共找到 1650 个簇。\n",
      "  - 13438 个属性被聚类\n",
      "  - 306 个属性未被聚类\n"
     ]
    }
   ],
   "source": [
    "# 对highest_df的高频词汇聚类，相似度较低，旨在为其构建上一级聚类\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# 计算句子嵌入\n",
    "embeddings = model.encode(highest_df['property'].tolist(), convert_to_tensor=True)\n",
    "#使用社区算法聚类\n",
    "results = perform_property_clustering(highest_df, column_name='property', similarity_threshold=0.5, min_community_size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e4119",
   "metadata": {},
   "source": [
    "0.3的相似度可以聚类到700个，\n",
    "0.5的相似度可以聚类到1650个，所以暂定一个值（可以为1650也可以是其他值，聚类后用大语言模型统一命名）\n",
    "然后对最高频的1650个进行聚类，得到的结果是1650个聚类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02b20742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未聚类项目保存到: high_unclustered_properties.csv\n",
      "聚类结果保存到: high_property_clusters_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存高频词蒸馏结果\n",
    "\n",
    "def save_clustering_results(results, base_path):\n",
    "    \"\"\"保存聚类结果到CSV文件\"\"\"\n",
    "    \n",
    "    # 保存聚类结果\n",
    "    clusters_data = []\n",
    "    for cluster in results['clustered_results']:\n",
    "        for member in cluster['members']:\n",
    "            clusters_data.append({\n",
    "                'cluster_id': cluster['cluster_id'],\n",
    "                'property': member['property'],\n",
    "                'count': member['count'],\n",
    "                'cluster_size': cluster['size']\n",
    "            })\n",
    "    \n",
    "    clusters_df = pd.DataFrame(clusters_data)\n",
    "    clusters_path = os.path.join(base_path, 'high_property_clusters_results.csv')\n",
    "    clusters_df.to_csv(clusters_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    # 保存未聚类项目\n",
    "    if results['unclustered_items']:\n",
    "        unclustered_df = pd.DataFrame(results['unclustered_items'])\n",
    "        unclustered_path = os.path.join(base_path, 'high_unclustered_properties.csv')\n",
    "        unclustered_df.to_csv(unclustered_path, index=False, encoding='utf-8')\n",
    "        print(f\"未聚类项目保存到: {unclustered_path}\")\n",
    "    \n",
    "    print(f\"聚类结果保存到: {clusters_path}\")\n",
    "\n",
    "# 保存结果\n",
    "base_path = os.path.dirname('data_anlyze')\n",
    "save_clustering_results(results, base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7034d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_extra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
